{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from https://blog.paperspace.com/beginners-guide-to-boltzmann-machines-pytorch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "%matplotlib inline # uncomment if you run in Jupyter notebook.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('./data',\n",
    "    train=True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor()])\n",
    "     ),\n",
    "     batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('./data',\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "    ),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "   def __init__(self,\n",
    "               n_vis=784,\n",
    "               n_hin=500,\n",
    "               k=5):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hin,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n",
    "        self.k = k\n",
    "    \n",
    "   def sample_from_p(self,p):\n",
    "       return torch.relu(torch.sign(p - Variable(torch.rand(p.size())).to(device)))\n",
    "    \n",
    "   def v_to_h(self,v):\n",
    "        p_h = torch.sigmoid(F.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_from_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "   def h_to_v(self,h):\n",
    "        p_v = torch.sigmoid(F.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_from_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "   def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_\n",
    "    \n",
    "   def free_energy(self,v):\n",
    "        vbias_term = v.mv(self.v_bias) # torch.mv: Matrix-Vector product\n",
    "        wx_b = F.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()\n",
    "\n",
    "def show_and_save(file_name,img):\n",
    "    npimg = np.transpose(img.numpy(),(1,2,0))\n",
    "    f = \"./%s.png\" % file_name\n",
    "    plt.imshow(npimg)\n",
    "    plt.imsave(f,npimg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model on GPU (if available)\n",
    "rbm = RBM(k=1).to(device)\n",
    "\n",
    "# Train using SGD\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    loss_ = []\n",
    "    for _, (data,target) in enumerate(train_loader):\n",
    "        data = Variable(data.view(-1,784))\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        sample_data = data.bernoulli()\n",
    "        \n",
    "        v,v1 = rbm(sample_data)\n",
    "        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "        loss_.append(loss.data.cpu())\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "    \n",
    "    # Create a preview of this iteration's \"dream\"\n",
    "    show_and_save(\"generate{}\".format(epoch),make_grid(v1.view(32,1,28,28).data.cpu()))\n",
    "    print(\"Training loss for {} epoch: {}\".format(epoch, np.mean(loss_)))\n",
    "\n",
    "show_and_save(\"real{}\",make_grid(v.view(32,1,28,28).data.cpu()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('pytorch-fastgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ffec6d55e9e0110e961cb003130d9be4f5d9c3975d01813a1861280f761e22f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
