# Class 10.1: Text processing and RNNs

* Overview paper on [Metrics](https://link.springer.com/article/10.1007/s11063-022-10835-4) for text translation and text generation models

# Class 10.2: Learning paradigms: How to train a neural network?

## Supervised
* Influence of label quality
* Bias/distribution shift: [Causality matters](https://www.nature.com/articles/s41467-020-17478-w) not only in medical imaging

## Semi-supervised/weakly supervised
* Multiple-instance learning
* [Blog on semi-supervised/weakly supervised learning](https://lilianweng.github.io/posts/2021-12-05-semi-supervised/) (Lilian Weng, 2021; three parts)

## Unsupervised/Self-Supervised
* Classification/Segmentation: Clustering
* Generative networks: Reconstruction (e.g. Autoencoders, will be touched in [Class 9](Class9.md))
* Distribution estimation models (e.g. RBMs using Contrastive Divergence, [Class 3](Class3.md), or [energy-based models](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html))
* Facebook's general framework for self-supervised learning, [data2vec](https://ai.facebook.com/research/publications/data2vec-a-general-framework-for-self-supervised-learning-in-speech-vision-and-language/)
* UvA Tutorial on [SimCLR](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial17/SimCLR.html)
* Pretraining algorithms, e.g. BERT-style
* Great blog post: [Self-Supervised Representation Learning](https://lilianweng.github.io/posts/2019-11-10-self-supervised/) (Lilian Weng, 2019)



## Problems with GANs

* 

## Score-based (energy) models

* Denoising Diffusion [video with Colab code](https://www.youtube.com/watch?v=a4Yfz2FxXiY) and [video with the maths](https://www.youtube.com/watch?v=HoKDTa5jHvg)
* Score matching [blog post](https://ajolicoeur.wordpress.com/the-new-contender-to-gans-score-matching-with-langevin-sampling/)
